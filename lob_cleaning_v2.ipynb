{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e842a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FILE   = \"originals/Raw international financial data_FY22-25.xlsx\"\n",
    "RAW_SHEET  = \"FY25 Mar Est - Europe (2)\"\n",
    "\n",
    "REF_FILE   = \"originals/CLN_FY25_International - products ONLY.xlsx\"\n",
    "REF_SHEET  = \"CLN - EU - Products ONLY\"\n",
    "\n",
    "OUTPUT_DIR   = \"outputs\"\n",
    "OUTPUT_XLSX  = f\"{OUTPUT_DIR}/cleaned_products_eu.xlsx\"\n",
    "OUTPUT_CSV   = f\"{OUTPUT_DIR}/cleaned_products_eu.csv\"\n",
    "OUTPUT_SHEET = \"AUTO_CLEAN\"\n",
    "\n",
    "BRACKETS = [\n",
    "    (25,   \"0-25K\"),\n",
    "    (49,   \"26-49K\"),\n",
    "    (100,  \"50-100K\"),\n",
    "    (249,  \"101-249K\"),\n",
    "    (499,  \"250-499K\"),\n",
    "    (float(\"inf\"), \"500+\")\n",
    "]\n",
    "\n",
    "FINAL_COLS = [\n",
    "    \"Region\",\"LOB\",\"Combined SW #\",\"Partner\",\"Category\",\"Primary territory\",\n",
    "    \"Start date\",\"End date\",\"Bracket\",\"Lifecycle\",\"High / Med/Low touch\",\"Details\",\n",
    "    \"Net revenue\",\"0-25K\",\"26-49K\",\"50-100K\",\"101-249K\",\"250-499K\",\"500+\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_header(sheet: str, marker: str = \"Sub Dept\", lookahead: int = 60) -> int:\n",
    "    \"\"\"Return the (zero-based) header row index that contains *marker*.\"\"\"\n",
    "    tmp = pd.read_excel(RAW_FILE, sheet, header=None, nrows=lookahead)\n",
    "    row = tmp.index[tmp.iloc[:, 0].astype(str).str.contains(marker, na=False)]\n",
    "    if row.empty:\n",
    "        raise ValueError(\"Could not find header row for sheet → \" + sheet)\n",
    "    return int(row[0])\n",
    "\n",
    "\n",
    "def load_raw() -> pd.DataFrame:\n",
    "    hdr = detect_header(RAW_SHEET)\n",
    "    df  = pd.read_excel(RAW_FILE, RAW_SHEET, header=hdr)\n",
    "\n",
    "    # trim pesky whitespace everywhere early\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    mask = (\n",
    "        df[\"Sub Dept\"].str.contains(\"Product\", case=False, na=False)\n",
    "        & ~df[\"Sub Dept\"].str.contains(\"Total\",  case=False, na=False)\n",
    "    )\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "RENAME = {\n",
    "    \"Licensee\"        : \"Partner\",\n",
    "    \"Product Category\": \"Category\",\n",
    "    \"Primary Territory\": \"Primary territory\",\n",
    "    \"SW #\"            : \"Combined SW #\",\n",
    "    \"Net Revenue\"     : \"Net revenue\",\n",
    "    \"Start Date\"      : \"Start date\",\n",
    "    \"End Date\"        : \"End date\",\n",
    "}\n",
    "\n",
    "\n",
    "# def aggregate_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Roll-up exact duplicates *before* we start fiddling with IDs.\"\"\"\n",
    "#     key = [\"Partner\",\"Combined SW #\",\"Category\",\"Start date\",\"End date\"]\n",
    "#     out = (\n",
    "#         df.groupby(key, dropna=False, as_index=False)\n",
    "#           .agg({\n",
    "#               \"Net revenue\"      : \"sum\",\n",
    "#               \"Primary territory\": (lambda s: \", \".join(sorted(set(s.dropna()))))\n",
    "#           })\n",
    "#     )\n",
    "#     return out\n",
    "\n",
    "def aggregate_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Roll-up exact duplicates, **except** leave each “New Business” /\n",
    "    placeholder deal as its own commercial line (only collapse if the\n",
    "    FINANCE sheet literally duplicated the same territory row).\n",
    "    \"\"\"\n",
    "    base_key = [\"Partner\", \"Combined SW #\", \"Category\",\n",
    "                \"Start date\", \"End date\"]\n",
    "\n",
    "    nb_mask  = df[\"Partner\"].str.lower() == \"new business\"\n",
    "    regular  = df.loc[~nb_mask]\n",
    "    newbiz   = df.loc[ nb_mask]\n",
    "\n",
    "    # ―― normal roll-up (territories concatenated) ―――――――――――――――――――\n",
    "    regular_out = (\n",
    "        regular.groupby(base_key, dropna=False, as_index=False)\n",
    "               .agg({\"Net revenue\": \"sum\",\n",
    "                     \"Primary territory\":\n",
    "                         lambda s: \", \".join(sorted(set(s.dropna())))})\n",
    "    )\n",
    "\n",
    "    # ―― “New Business”: keep one row per territory ―――――――――――――――――――\n",
    "    nb_key = base_key + [\"Primary territory\"]\n",
    "    newbiz_out = (\n",
    "        newbiz.groupby(nb_key, dropna=False, as_index=False)\n",
    "               .agg({\"Net revenue\": \"sum\"})\n",
    "    )\n",
    "\n",
    "    return pd.concat([regular_out, newbiz_out], ignore_index=True)\n",
    "\n",
    "def assign_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    id_counter = defaultdict(int)\n",
    "    blank_it   = itertools.count(1)\n",
    "    tbd_it     = itertools.count(1)\n",
    "    new_ids    = []\n",
    "\n",
    "    for base_raw, partner in zip(df[\"_base\"], df[\"Partner\"], strict=False):\n",
    "        base = str(base_raw).strip()\n",
    "        base_up = base.upper()         # <--- NEW (1)  normalise once\n",
    "\n",
    "        # ---------- placeholder logic -------------------------\n",
    "        if base_up in {\"\", \"NAN\", \"NONE\", \"TB\", \"TBD\"}:   # <--- NEW (2)\n",
    "            if str(partner).strip().lower() == \"new business\":\n",
    "                new_ids.append(f\"Blank {next(blank_it)}\")\n",
    "            elif str(partner).lower().startswith(\"fx gain\"):\n",
    "                new_ids.append(\"FX Gain(Loss)\")\n",
    "            else:\n",
    "                new_ids.append(f\"TBD{next(tbd_it)}\")\n",
    "            continue\n",
    "\n",
    "        seq = id_counter[base_up]\n",
    "        suffix = \"\" if seq == 0 else string.ascii_uppercase[seq - 1]\n",
    "        new_ids.append(f\"{base_up}{suffix}\")\n",
    "        id_counter[base_up] += 1        # <--- change key to *base_up*  (3)\n",
    "\n",
    "    df[\"Combined SW #\"] = new_ids\n",
    "    return df\n",
    "\n",
    "def rollup_fx(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collapse every row whose Partner starts with 'FX Gain' or 'FX Loss'\n",
    "    into a single template row (keeps the first one as shape template).\n",
    "    \"\"\"\n",
    "    mask = df[\"Partner\"].str.contains(r\"^FX Gain\", case=False, na=False)\n",
    "    if mask.sum() <= 1:\n",
    "        return df                      # already rolled-up or none present\n",
    "\n",
    "    total = df.loc[mask, \"Net revenue\"].sum()\n",
    "    row   = df.loc[mask].iloc[0].copy()\n",
    "    row[\"Net revenue\"] = total\n",
    "    # keep the first territory (or Benelux) so the line still has a place\n",
    "    row[\"Primary territory\"] = \"Benelux\"\n",
    "\n",
    "    return pd.concat([df.loc[~mask], row.to_frame().T], ignore_index=True)\n",
    "\n",
    "def add_brackets(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    bins, labels = zip(*BRACKETS, strict=False)\n",
    "    df[\"Bracket\"] = pd.cut(df[\"Net revenue\"], bins=[-np.inf, *bins], labels=labels)\n",
    "    for lab in labels:\n",
    "        df[lab] = (df[\"Bracket\"] == lab).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a41242",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = load_raw().rename(columns=RENAME)\n",
    "\n",
    "# date coercion -------------------------------------------------------------\n",
    "for col in (\"Start date\", \"End date\"):\n",
    "    raw[col] = pd.to_datetime(raw[col], errors=\"coerce\")\n",
    "\n",
    "# drop obviously placeholder rows (missing category) ------------------------\n",
    "raw = raw[raw[\"Category\"].notna()]\n",
    "\n",
    "# aggregate → suffix handling ------------------------------------------------\n",
    "agg = aggregate_rows(raw)\n",
    "agg[\"Region\"] = \"EUROPE\"\n",
    "agg[\"LOB\"]    = \"Products\"\n",
    "\n",
    "agg[\"_base\"] = (\n",
    "    agg[\"Combined SW #\"].fillna(\"\")\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[A-Z]$\", \"\", regex=True)  # strip any existing suffix\n",
    ")\n",
    "agg = agg.sort_values([\"_base\", \"Partner\"], kind=\"mergesort\")  # stable sort\n",
    "agg = rollup_fx(agg)\n",
    "agg = assign_ids(agg)\n",
    "\n",
    "# pad new manual‑only columns ----------------------------------------------\n",
    "for col in (\"Lifecycle\", \"High / Med/Low touch\", \"Details\"):\n",
    "    agg[col] = \"\"\n",
    "\n",
    "# brackets & final tidy -----------------------------------------------------\n",
    "agg = add_brackets(agg)\n",
    "final = agg[FINAL_COLS]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# outputs -------------------------------------------------------------------\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "final.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# make sure we overwrite cleanly if the file exists already\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\", mode=\"w\") as xls:\n",
    "    final.to_excel(xls, sheet_name=OUTPUT_SHEET, index=False)\n",
    "\n",
    "print(\"Saved →\", OUTPUT_CSV, \"and\", OUTPUT_XLSX)\n",
    "\n",
    "# quick sanity‑check against the manual reference ---------------------------\n",
    "if Path(REF_FILE).exists():\n",
    "    ref = pd.read_excel(REF_FILE, REF_SHEET, header=2)\n",
    "    ref = ref.loc[:, ~ref.columns.str.contains(r\"^Unnamed\")]  # <- FIXED LINE\n",
    "\n",
    "    print(\"\\n— sanity —\")\n",
    "    print(\"rows   ref / ours:\", ref.shape[0], \"/\", final.shape[0])\n",
    "    print(\n",
    "        \"total €k       :\",\n",
    "        round(ref[\"Net revenue\"].sum() / 1_000, 1), \"/\",\n",
    "        round(final[\"Net revenue\"].sum() / 1_000, 1),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0a5a5",
   "metadata": {},
   "source": [
    "# Interesting Examples\n",
    "- Blank 1 / Blank 2, \n",
    "- 12621\n",
    "- 13191"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4b8bb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jess-lob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
